{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "packed-ferry",
   "metadata": {},
   "source": [
    "# GazeClusterML\n",
    "\n",
    "### Authored by: Taimur Khan, Benjamin Nava HÃ¶er\n",
    "***Final Project for TU Berlin WU'20 course: Machine Learning using Python: Theory and Application**\n",
    "\n",
    "___**Licensed under:**___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-click",
   "metadata": {},
   "source": [
    "### 1. Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-kernel",
   "metadata": {},
   "source": [
    "Machine Learning(ML) methods have shown promissing results in the classification of eyetracking data into fixations and saccades. However, present ML models for such classsification are trained with data from eyetracking hardware, and hence do not perform well on webcam-based eyetrackng. Additonally, no labeled (fixations and saccades) dataset exists for webcam-based eyetracking data.\n",
    "\n",
    "Here, an unlabeled dataset of an eyetracking timeseries was clustered using the spatial clustering algorithms DBSCAN and OPTICS, as well as the spatio-temporal clustering algorithms ST-DBSCAN and ST-OPTICS. The silhouette score was not found to be the appropriate evaluation metric for the obtained clusterings. A second, heuristically hand-labelled dataset was used to evaluate the accuracy of the most promising algorithms ST-DBSCAN and ST-OPTICS. 75.38% of the predicted labels in ST-OPTICS and 85.02% with ST-DBSCAN matched the provided labels, making these a valuable tool for the labeling of webcam-based eyetracking data.\n",
    "\n",
    "Although ST-DBSCAN shows higher accuracy value, it must be noted that the hand-labeled dataset used to measure model accuracy contains equally spread out gaze points, as compared to \"wild\" eyetracking datasets where the data is not as equally spaced. The resulting variance in cluster densities might cause an accuracy loss for ST-DBSCAN in \"wild\" data. A further analysis of hand labaled datasets is suggested to create a better understanding of the performance difference between ST-OPTICS and ST-DBSCAN.\n",
    "\n",
    "![SegmentLocal](resources/3d-DBSCAN.gif \"segment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-progressive",
   "metadata": {},
   "source": [
    "### 2. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-thriller",
   "metadata": {},
   "source": [
    "**2.1. The Problem** \n",
    "\n",
    "Human eyes move in two natural events: Fixations and Saccades. However, event detection is a challenging stage in eye tracking data analysis. A major drawback of current event detection methods is that parameters have to be adjusted based on eye movement data quality. Such noise is even further exagerated in data gathered by Adsata's webcam-based eyetracking system (Webgazer), owing to low frequency and high noise data collection. Here we show that a fully automated clustering of raw gaze samples can help to create labeled datasets with clusters belonging to fixations or noise, using a machine-learning approach. Any already manually or algorithmically detected features of the dataset can then be used to further train a classifier to classify the saccades out of the noise clusters without the need for a user to set parameters. In this study, we explore the application of the following machine learning clustering methods for the detection of fixations:\n",
    "\n",
    "1. DBSCAN : Density-Based Spatial Clustering of Applications with Noise\n",
    "2. ST-DBSCAN : Spatio-Temporal Density-Based Spatial Clustering of Applications with Noise\n",
    "3. OPTICS: Ordering Points To Identify the Clustering Structure\n",
    "4. ST-OPTICS: Spatio-Temporal Ordering Points To Identify the Clustering Structure\n",
    "\n",
    "\n",
    "In an effort to show practical utility of the proposed method to the applications that employ eye movement classification algorithms, we provide an example where the method is employed in an eye movement-driven biometric application.\n",
    "\n",
    "___Fig 1:___ Data comparison between Webgazer and Tobii-Pro X3-120 \n",
    "\n",
    "\n",
    "<img src=\"resources\\problem.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-chancellor",
   "metadata": {},
   "source": [
    "**2.2. About the datasets**\n",
    "\n",
    "___Dataset 1___\n",
    "\n",
    "Dataset 1 is the primary dataset for Webgazer vs Tobii-Pro X3-120 study collected for Schreiber, 2020 [5] hosted by Adsata and Martin-Luther-University. This was done to evaluate the behavior of webgazer when the hardware detects a fixation or a saccade. However, the discrepancy between the frequency rates of the Tobii-Pro and Webgazer did not allow for labeling of Webgazer data that directly corresponded the data from Tobii-Pro. \n",
    "\n",
    "\n",
    "___Fig 2:___ Set-up for Schreiber 2020 [5]\n",
    "\n",
    "\n",
    "<img src=\"resources\\ds1-setup.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "\n",
    "___Fig 3:___ Sample results for Schreiber 2020 [5]\n",
    "\n",
    "<img src=\"resources\\ds1-results.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "___Dataset 2___\n",
    "\n",
    "This dataset uses a heuristic approach to \"hand label\" the data into fixations and saccades taken from Schreiber, 2020 [5]\n",
    "\n",
    "\n",
    "Heuristic:\n",
    "\n",
    "- Drag & Drop --> Saccade\n",
    "- Click --> Fixations\n",
    "\n",
    "\n",
    "___Fig 4:___ Heuristic method for \"hand labeling\" the data\n",
    "\n",
    "<img src=\"resources\\ds2.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "\n",
    "___Fig 5:___ Comparison of 2 samples collected for Dataset 2\n",
    "\n",
    "<img src=\"resources\\ds2-samples.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-melbourne",
   "metadata": {},
   "source": [
    "### 3. Theoretical Rationalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-redhead",
   "metadata": {},
   "source": [
    "#### 3.1 DBSCAN : Density-Based Spatial Clustering of Applications with Noise [3]\n",
    "DBSCAN discovers arbitrarily shaped clusters in a dataset using a radius value $\\epsilon$ based on a user defined distance measure, i.e. euclidean. Additionally, a MinPts value defines the minimal number of points that should occur within $\\epsilon$ radius. Given the neighborhood of $p$ as $N(p) := \\{q \\in D: d(p,q) \\leq \\epsilon\\}$ with $D := dataset$ and $p$ and $q$ as points therein, this leads to the following three kinds of points:\n",
    "- Core points: $\\mid N(p)\\mid \\geq MinPts$\n",
    "- Border points: $\\mid N(p)\\mid < MinPts$\n",
    "- Else: Noise\n",
    "\n",
    "Source code: https://github.com/scikit-learn/scikit-learn/blob/b3ea3ed6a/sklearn/cluster/_dbscan.py#L148\n",
    "\n",
    "#### 3.2 ST-DBSCAN : Spatio-Temporal Density-Based Spatial Clustering of Applications with Noise [2]\n",
    "ST-DBSCAN extends builds on DBSCAN by adding a second, temporal radius value $\\epsilon_{2}$. Analogous distance metrics as for $\\epsilon$ can be used, i.e. euclidean. The neighborhood of a point is now described by both $\\epsilon$ and $\\epsilon_{2}$: \n",
    "\n",
    "$N(p) := \\{q \\in D: d_{1}(p,q) \\leq \\epsilon_{1},d_{2}(p,q) \\leq \\epsilon_{2}\\}$\n",
    "\n",
    "Thereupon the points in the dataset will be classified according to the above mentioned categories.\n",
    "\n",
    "Source Code: https://github.com/eren-ck/st_dbscan\n",
    "\n",
    "#### 3.3 OPTICS: Ordering Points To Identify the Clustering Structure [1]\n",
    "\n",
    "The OPTICS algorithm shares many similarities with the DBSCAN algorithm, and can be considered a generalization of DBSCAN that relaxes the eps requirement from a single value to a value range. The key difference between DBSCAN and OPTICS is that the OPTICS algorithm builds a reachability graph, which assigns each sample both a reachability_ distance, and a spot within the cluster ordering_ attribute; these two attributes are assigned when the model is fitted, and are used to determine cluster membership. If OPTICS is run with the default value of inf set for max_eps, then DBSCAN style cluster extraction can be performed repeatedly in linear time for any given eps value using the cluster_optics_dbscan method. Setting max_eps to a lower value will result in shorter run times, and can be thought of as the maximum neighborhood radius from each point to find other potential reachable points.\n",
    "\n",
    "Source code: https://github.com/scikit-learn/scikit-learn/blob/b3ea3ed6a/sklearn/cluster/_optics.py#L24\n",
    "\n",
    "#### 3.4 ST-OPTICS: Spatio-Temporal Ordering Points To Identify the Clustering Structure [4]\n",
    "\n",
    "ST-OPTICS extends OPTICS by also taking a temporal radius into the calculation.\n",
    "\n",
    "Source code: https://github.com/eren-ck/st_optics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-porcelain",
   "metadata": {},
   "source": [
    "### 4. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-guest",
   "metadata": {},
   "source": [
    "**4.0. Setup Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    " # OPTIONAL: Python package installations\n",
    "    \n",
    "!pip install st-dbscan #https://github.com/eren-ck/st_dbscan\n",
    "!pip install ipympl\n",
    "!pip install st_optics #https://github.com/eren-ck/st_optics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "subtle-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import project dependencies\n",
    "\n",
    "import json\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN, OPTICS, cluster_optics_dbscan\n",
    "from st_dbscan import ST_DBSCAN\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import silhouette_score\n",
    "from st_dbscan import ST_DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import animation\n",
    "from st_optics import ST_OPTICS\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-application",
   "metadata": {},
   "source": [
    "**4.1. Load and explore data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "environmental-princess",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     timestamp            x           y     label\n",
       " 0       102708   986.288075  508.004755  Fixation\n",
       " 1       102781  1005.492167  495.522600  Fixation\n",
       " 2       102842   942.353008  492.123891  Fixation\n",
       " 3       102893   948.193646  474.714589  Fixation\n",
       " 4       102943   938.728917  481.875697  Fixation\n",
       " ..         ...          ...         ...       ...\n",
       " 968     163046   904.812802  246.252619   Saccade\n",
       " 969     163105   861.176955  262.574859  Fixation\n",
       " 970     163155   732.960155  276.037371  Fixation\n",
       " 971     163239   635.075056  295.309572   Saccade\n",
       " 972     163289   618.075163  313.958367  Fixation\n",
       " \n",
       " [973 rows x 4 columns],\n",
       "      timestamp           x           y     label\n",
       " 0        39342  739.023953  417.475902  fixation\n",
       " 1        39380  707.481049  444.210737  fixation\n",
       " 2        39424  713.926225  445.593758  fixation\n",
       " 3        39469  704.775582  469.488595  fixation\n",
       " 4        39507  704.159921  476.988842  fixation\n",
       " ..         ...         ...         ...       ...\n",
       " 836      75791  610.012227  260.745510   saccade\n",
       " 837      75841  677.415175  327.846551   saccade\n",
       " 838      75883  674.590945  369.156196   saccade\n",
       " 839      75924  671.668082  416.032663  fixation\n",
       " 840      75961  684.261518  428.946405  fixation\n",
       " \n",
       " [841 rows x 4 columns])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Dataset 1 and store in dataframe 'df1'\n",
    "url1 = urllib.request.urlopen(\"http://dschr.de/api/resultCombineData\")\n",
    "data1 = json.loads(url1.read().decode())\n",
    "df1 = pd.DataFrame(data1[0][\"data\"])\n",
    "\n",
    "# Loading Dataset 2 and store in dataframe 'df2'\n",
    "url2 = urllib.request.urlopen(\"http://dschr.de/api/handLabeled\")\n",
    "data2 = json.loads(url2.read().decode())\n",
    "df2 = pd.DataFrame(data2[0][\"data\"])\n",
    "\n",
    "\n",
    "df1, df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-alpha",
   "metadata": {},
   "source": [
    "**4.2. Preprocess data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "isolated-addition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 986.2880749379, 508.0047550332, 'Fixation'],\n",
       "        [73, 1005.4921671685, 495.5226000186, 'Fixation'],\n",
       "        [134, 942.3530079831, 492.1238913635, 'Fixation'],\n",
       "        ...,\n",
       "        [60447, 732.960154917, 276.0373709741, 'Fixation'],\n",
       "        [60531, 635.0750563979, 295.3095717554, 'Saccade'],\n",
       "        [60581, 618.0751626144, 313.9583669145, 'Fixation']], dtype=object),\n",
       " array([[0, 739.0239530773961, 417.4759015313773, 'fixation'],\n",
       "        [38, 707.4810489651718, 444.2107367829889, 'fixation'],\n",
       "        [82, 713.9262252699162, 445.593757589654, 'fixation'],\n",
       "        ...,\n",
       "        [36541, 674.5909449373224, 369.15619639448806, 'saccade'],\n",
       "        [36582, 671.6680822153079, 416.0326625889876, 'fixation'],\n",
       "        [36619, 684.2615176944689, 428.94640490405294, 'fixation']],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting timestamps in both dataframes to start at 0\n",
    "df1['timestamp'] = df1['timestamp'].apply(lambda x: x - df1['timestamp'][0]) \n",
    "df2['timestamp'] = df2['timestamp'].apply(lambda x: x - df2['timestamp'][0])\n",
    "\n",
    "#Convert dataframes to numpy arrays\n",
    "array1 = df1.to_numpy()\n",
    "array2 = df2.to_numpy()\n",
    "\n",
    "array1, array2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-dairy",
   "metadata": {},
   "source": [
    "**4.3. Configuring Models & Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "commercial-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup DBSCAN classifier\n",
    "eps_dbscan=150\n",
    "min_samples_dbscan=5\n",
    "\n",
    "clf_dbscan = DBSCAN(eps=eps_dbscan, min_samples=min_samples_dbscan, metric='euclidean', algorithm='auto', leaf_size=30, p=2, n_jobs=1)\n",
    "\n",
    "# Setup ST-DBSCAN classifier\n",
    "eps_stdbscan=70\n",
    "eps2_stdbscan=250\n",
    "min_samples_stdbscan=5\n",
    "\n",
    "clf_st_dbscan = ST_DBSCAN(eps1=eps_stdbscan, eps2=eps2_stdbscan, min_samples=min_samples_stdbscan) \n",
    "\n",
    "# Setup OPTICS classifier\n",
    "xi_optics = 0.05\n",
    "max_eps_optics = 180\n",
    "min_cluster_size_optics = 5\n",
    "min_samples_optics = 4\n",
    "\n",
    "clf_optics = OPTICS(cluster_method = 'xi', xi= xi_optics, max_eps= max_eps_optics, min_cluster_size = min_cluster_size_optics, min_samples=min_samples_optics, metric='euclidean', algorithm='auto', p=2)\n",
    "\n",
    "# Setup ST-OPTICS classifier\n",
    "xi_stoptics = 0.2\n",
    "eps2_stoptics = 250\n",
    "min_samples = 4\n",
    "\n",
    "clf_st_optics = ST_OPTICS(xi = 0.08, eps2 = 250, min_samples = 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-dragon",
   "metadata": {},
   "source": [
    "**4.4. Train model with Dataset 1 and predict labels**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-beast",
   "metadata": {},
   "source": [
    "##### 4.4.1 DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "banner-bottle",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b7f7aecc9e41a58be0940fb1889f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7fbbb6e6ee10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_dbscan.fit(df1.iloc[:,:3])\n",
    "\n",
    "labels_pred_dbscan = clf_dbscan.labels_\n",
    "\n",
    "for i in range(labels_pred_dbscan.size):\n",
    "    if labels_pred_dbscan[i] >= 0:\n",
    "        labels_pred_dbscan[i] = 1\n",
    "\n",
    "          \n",
    "%matplotlib widget\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(df1.iloc[:,1],df1.iloc[:,2],df1.iloc[:,0], c=labels_pred_dbscan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-preservation",
   "metadata": {},
   "source": [
    "##### 4.4.2 ST-DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "spiritual-behalf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532e417097084f27bc1205ddc3fee975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7fbbb6e26390>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_st_dbscan.fit(df1.iloc[:,:3])\n",
    "\n",
    "labels_pred_stdbscan = clf_st_dbscan.labels\n",
    "\n",
    "for i in range(labels_pred_stdbscan.size):\n",
    "    if labels_pred_stdbscan[i] >= 0:\n",
    "        labels_pred_stdbscan[i] = 1\n",
    "\n",
    "          \n",
    "%matplotlib widget\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(df1.iloc[:,1],df1.iloc[:,2],df1.iloc[:,0], c=labels_pred_stdbscan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-drilling",
   "metadata": {},
   "source": [
    "**4.4.3 OPTICS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "worth-ready",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1f045974c64c4cbc2b461707e09d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7fbbbb1aa2d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "labels_pred_optics = clf_optics.fit_predict(df1.iloc[:,:3])\n",
    "\n",
    "for i in range(labels_pred_optics.size):\n",
    "    if labels_pred_optics[i] >= 0:\n",
    "        labels_pred_optics[i] = 1\n",
    "\n",
    "%matplotlib widget\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(df1.iloc[:,1],df1.iloc[:,2],df1.iloc[:,0], c=labels_pred_optics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-instruction",
   "metadata": {},
   "source": [
    "**4.4.4 ST-OPTICS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "diverse-synthesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02de1d43b1c14013ad45ed16ccb419a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7fbbbb1aafd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_st_optics.fit(df1.iloc[:,:3])\n",
    "\n",
    "labels_pred_stoptics = clf_st_optics.labels\n",
    "\n",
    "for i in range(labels_pred_stoptics.size):\n",
    "    if labels_pred_stoptics[i] >= 0:\n",
    "        labels_pred_stoptics[i] = 1\n",
    "\n",
    "%matplotlib widget\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(df1.iloc[:,1],df1.iloc[:,2],df1.iloc[:,0], c=labels_pred_stoptics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-greene",
   "metadata": {},
   "source": [
    "### 5. Evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-spider",
   "metadata": {},
   "source": [
    "   **5.1 Silhouette Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "elegant-reduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette scores:\n",
      "DBSCAN: 0.004875167353651087\n",
      "ST-DBSCAN: 0.017654084873375348\n",
      "OPTICS: 0.007203188751228375\n",
      "ST-OPTICS: -0.01743249133026968\n"
     ]
    }
   ],
   "source": [
    "# Silhouette score DBSCAN\n",
    "ss_dbscan = silhouette_score(df1.iloc[:,:3],labels_pred_dbscan)\n",
    "\n",
    "# Silhouette score ST-DBSCAN\n",
    "ss_stdbscan = silhouette_score(df1.iloc[:,:3],labels_pred_stdbscan)\n",
    "\n",
    "# Silhouette score OPTICS\n",
    "ss_optics = silhouette_score(df1.iloc[:,:3],labels_pred_optics)\n",
    "\n",
    "# Silhouette score ST-OPTICS\n",
    "ss_stoptics = silhouette_score(df1.iloc[:,:3],labels_pred_stoptics)\n",
    "print(f\"Silhouette scores:\\nDBSCAN: {ss_dbscan}\\nST-DBSCAN: {ss_stdbscan}\\nOPTICS: {ss_optics}\\nST-OPTICS: {ss_stoptics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-worcester",
   "metadata": {},
   "source": [
    "   **5.2 Accuracy in respect to hand-labeled data from Dataset 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-senior",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing Dataset 1\n",
    "x = df2.iloc[:,1].to_numpy()\n",
    "y = df2.iloc[:,2].to_numpy()\n",
    "ts = df2.iloc[:,0].to_numpy()\n",
    "labels = df2.iloc[:,3].to_numpy()\n",
    "\n",
    "predics = labels\n",
    "\n",
    "# Decoding labels to binary values\n",
    "\n",
    "for i in range(predics.size):\n",
    "    if predics[i] == \"fixation\":\n",
    "        predics[i] = 1\n",
    "    if predics[i] == \"saccade\":\n",
    "        predics[i] = 0\n",
    "\n",
    "\n",
    "        \n",
    "# Converting labels to integers\n",
    "y_true = predics.astype(int)\n",
    "\n",
    "# Fitting to DBSCAN with Dataset 1\n",
    "clf_dbscan.fit(df2.iloc[:,:3])\n",
    "\n",
    "y_pred_dbscan = clf_dbscan.labels_\n",
    "\n",
    "\n",
    "for i in range(y_pred_dbscan.size):\n",
    "    if y_pred_dbscan[i] >= 0:\n",
    "        y_pred_dbscan[i] = 1\n",
    "    elif y_pred_dbscan[i] <= 0:\n",
    "        y_pred_dbscan[i] = 0\n",
    "\n",
    "# Fitting to ST-DBSCAN with Dataset 1\n",
    "clf_st_dbscan.fit(df2.iloc[:,:3])\n",
    "\n",
    "y_pred_stdbscan = clf_st_dbscan.labels\n",
    "\n",
    "\n",
    "for i in range(y_pred_stdbscan.size):\n",
    "    if y_pred_stdbscan[i] >= 0:\n",
    "        y_pred_stdbscan[i] = 1\n",
    "    elif y_pred_stdbscan[i] <= 0:\n",
    "        y_pred_stdbscan[i] = 0\n",
    "\n",
    "\n",
    "# Fitting to OPTICS with Dataset 1\n",
    "clf_optics.fit(df2.iloc[:,:3])\n",
    "\n",
    "y_pred_optics = clf_optics.labels_\n",
    "\n",
    "\n",
    "for i in range(y_pred_optics.size):\n",
    "    if y_pred_optics[i] >= 0:\n",
    "        y_pred_optics[i] = 1\n",
    "    elif y_pred_optics[i] <= 0:\n",
    "        y_pred_optics[i] = 0\n",
    "\n",
    "\n",
    "\n",
    "# Fitting to ST-OPTICS with Dataset 1\n",
    "clf_st_optics.fit(df2.iloc[:,:3])\n",
    "\n",
    "y_pred_stoptics = clf_st_optics.labels\n",
    "\n",
    "\n",
    "for i in range(y_pred_stoptics.size):\n",
    "    if y_pred_stoptics[i] >= 0:\n",
    "        y_pred_stoptics[i] = 1\n",
    "    elif y_pred_stoptics[i] <= 0:\n",
    "        y_pred_stoptics[i] = 0\n",
    "\n",
    "        \n",
    "acc_dbscan = accuracy_score(y_true, y_pred_dbscan)\n",
    "acc_stdbscan = accuracy_score(y_true, y_pred_stdbscan)\n",
    "acc_optics = accuracy_score(y_true, y_pred_optics)\n",
    "acc_stoptics = accuracy_score(y_true, y_pred_stoptics)\n",
    "\n",
    "\n",
    "print(\"Accuracy of Clustering with DBSCAN:\", acc_dbscan*100)\n",
    "print(\"Accuracy of Clustering with ST-DBSCAN:\", acc_stdbscan*100)\n",
    "print(\"Accuracy of Clustering with OPTICS:\", acc_optics*100)\n",
    "print(\"Accuracy of Clustering with ST-OPTICS:\", acc_stoptics*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-bosnia",
   "metadata": {},
   "source": [
    "### 6. Conclusions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"ml-labels\"] = y_pred\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-constitutional",
   "metadata": {},
   "source": [
    "### 7. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-ethiopia",
   "metadata": {},
   "source": [
    "1. Ankerst, M., Breunig, M. M., Kriegel, H. P., & Sander, J. (1999). OPTICS: ordering points to identify the clustering structure. ACM Sigmod record, 28(2), 49-60.\n",
    "2. Birant, Derya, and Alp Kut. (2007) \"ST-DBSCAN: An algorithm for clustering spatialâtemporal data.\" Data & Knowledge Engineering 60.1: 208-221.\n",
    "3. Ester, M., H. P. Kriegel, J. Sander, and X. Xu, (1996) \"A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise\". In: Proceedings of the 2nd International Conference on Knowledge Discovery and Data Mining, Portland, OR, AAAI Press, pp. 226-231.\n",
    "4. Peca, I., Fuchs, G., Vrotsou, K., Andrienko, N. V., & Andrienko, G. L. (2012). Scalable Cluster Analysis of Spatial Events. In EuroVA@ EuroVis.\n",
    "5. Schreiber, D. (2020) \"Klassifizierung von okulomotorischen Ereignissen (Fixierungen und Sakkaden)in webcam-basierten Eye-Tracking Daten\". Martin-Luther-Univeristy Halle-Wittenberg. \n",
    "6. Zemblys, Raimondas, et al. (2018)\"Using machine learning to detect events in eye-tracking data.\" Behavior research methods 50.1 : 160-181."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-factory",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
